{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 02 : Régression linéaire \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I Régression linéaire à une seule variable \n",
    "Dans cette partie, on commence par implémenter la régression linéaire avec une seule variable de prédiction (predictor). Nous allons donc essayer de résoudre le fameux problème de prédiction du prix d'une maison en connaissant sa superficie. \n",
    "\n",
    "### I.1 Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.1.1 Lecture des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Superficie</th>\n",
       "      <th>Prix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2104</td>\n",
       "      <td>399900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1600</td>\n",
       "      <td>329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2400</td>\n",
       "      <td>369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1416</td>\n",
       "      <td>232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3000</td>\n",
       "      <td>539900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Superficie    Prix\n",
       "0        2104  399900\n",
       "1        1600  329900\n",
       "2        2400  369000\n",
       "3        1416  232000\n",
       "4        3000  539900"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = [\"Superficie\", \"Prix\"]\n",
    "houses = pd.read_csv(\"datasets/houses.csv\", names=header)\n",
    "houses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Superficie</th>\n",
       "      <th>Prix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2000.680851</td>\n",
       "      <td>340412.659574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>794.702354</td>\n",
       "      <td>125039.899586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>852.000000</td>\n",
       "      <td>169900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1432.000000</td>\n",
       "      <td>249900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1888.000000</td>\n",
       "      <td>299900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>2269.000000</td>\n",
       "      <td>384450.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>4478.000000</td>\n",
       "      <td>699900.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Superficie           Prix\n",
       "count    47.000000      47.000000\n",
       "mean   2000.680851  340412.659574\n",
       "std     794.702354  125039.899586\n",
       "min     852.000000  169900.000000\n",
       "25%    1432.000000  249900.000000\n",
       "50%    1888.000000  299900.000000\n",
       "75%    2269.000000  384450.000000\n",
       "max    4478.000000  699900.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I.1.2 Normalisation \n",
    "La normalisation est la mise à echelle des valeurs des caractéristiques. Exemple simple de but : En calculant la distance euclidienne une des caracteristiques va avoir plus d'effet sur le résultat si ses valeurs sont beaucoup plus grandes que celle de l'autre variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.        , -1.35873244],\n",
       "        [-1.22474487,  1.01904933],\n",
       "        [ 1.22474487,  0.33968311]]),\n",
       " array([2., 7.]),\n",
       " array([0.81649658, 2.94392029]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalisation\n",
    "# la fonction qui applique le Z-score sur une matrice \n",
    "# La fonction doit retourner 3 résultats \n",
    "# 1: la matrice normalisée, 2: la moyenne, 3: la déviation standard \n",
    "def normalise(X): \n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    return (X-mean)/std, mean, std\n",
    "\n",
    "\n",
    "# Doit afficher: \n",
    "\"\"\"\n",
    "(array([[ 0.        , -1.35873244],\n",
    "        [-1.22474487,  1.01904933],\n",
    "        [ 1.22474487,  0.33968311]]),\n",
    " array([2., 7.]),\n",
    " array([0.81649658, 2.94392029]))\n",
    "\"\"\"\n",
    "normalise([[2., 3.], [1., 10.], [3., 8]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I.1.3 Fractionnement des données \n",
    "Ici, on va diviser les données en données de test et d'entrainnement \n",
    "\n",
    "On prend juste les 7 dernières ligne pour le  test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36, 1), (36,), (11, 1), (11,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraction des caractéristiques \n",
    "def fractionner(df):\n",
    "    X = df.iloc[:, :-1].values # Premières colonnes \n",
    "    Y = df.iloc[:,-1].values # Dernière colonne \n",
    "    # On définit la matrice X comme etant la supérficie concatenée à un vecteur de 1 \n",
    "    # pour faciliter l'algorithme pour theta0 \n",
    "    return X, Y\n",
    "\n",
    "# Randomization des données pour marquer les 80% lignes\n",
    "msk = np.random.rand(len(houses)) < 0.8 \n",
    "\n",
    "X_train, Y_train = fractionner(houses[msk])\n",
    "X_test, Y_test = fractionner(houses[~msk])\n",
    "\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Les données d'entrainnement en bleu\n",
    "plt.scatter(X_train, Y_train, color=\"blue\")\n",
    "# Les données de test en rouge\n",
    "plt.scatter(X_test, Y_test, color=\"red\")\n",
    "plt.xlabel('Superficie')\n",
    "plt.ylabel('Prix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2 Descente du gradient \n",
    "\n",
    "#### I.2.1 Définir les paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.309554])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Définir les hyperparamétres : \n",
    "LEARNING_RATE = 0.01 \n",
    "NB_ITER = 500\n",
    "\n",
    "# TODO :  Initialiser aléatoirement les paramètres :\n",
    "## theta est une liste contenant les paramètres theta (le nombre des colonnes)\n",
    "#des caractéristiques de X + 1 (pour theta0)\n",
    "theta = np.random.rand(X_train.shape[1])\n",
    "# Affichage des paramètres initiales (5 premières lignes)\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.2.2 Définir les fonctions nécessaires pour la regression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.75, 5.25, 4.25])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Prédire la valeur : \n",
    "def predire(X, theta):\n",
    "    return np.dot(X, theta)\n",
    "\n",
    "# tester la prédiction \n",
    "X_t = np.array([[1., 5.], [1., 10.], [1., 8]])\n",
    "theta_t = np.array([0.25, 0.5])\n",
    "# Le résulat doit être\n",
    "\"\"\"\n",
    "array([2.75, 5.25, 4.25])\n",
    "\"\"\"\n",
    "predire(X_t, theta_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Définir la fonction de cout : \n",
    "def J(X, Y, theta):\n",
    "    return np.mean((Y - predire(X, theta))**2)/2 \n",
    "\n",
    "# tester le cout \n",
    "#X_t = np.array([[1., 5.], [1., 10.], [1., 8]])\n",
    "#theta_t = np.array([0.25, 0.5])\n",
    "Y_t = np.array([3., 5., 4.5])\n",
    "# Le résulat doit être ((3-2.75)^2 + (5-5.25)^2 + (4.5-4.25)^2))/6\n",
    "\"\"\"\n",
    "0.03125\n",
    "\"\"\"\n",
    "J(X_t, Y_t, theta_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08333333, -0.25      ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Définir la fonction de gradient :\n",
    "def gradient(X, Y, theta):\n",
    "    error = (predire(X, theta)-Y)/X.shape[0]\n",
    "    return  np.dot(X.T, error)\n",
    "# Tester le gradient, le résultat doit être\n",
    "\"\"\"\n",
    "array([-0.08333333, -0.25      ])\n",
    "\"\"\"\n",
    "gradient(X_t, Y_t, theta_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def afficher_droite(X, Y, theta):\n",
    "    plt.scatter(X[:,1], Y, color=\"blue\")\n",
    "    plt.plot(X[:,1], predire(X, theta), color=\"red\")\n",
    "    plt.show()\n",
    "# tester avec X_t et Y_t\n",
    "afficher_droite(X_t, Y_t, theta_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.25202765, 0.50363117]),\n",
       " [0.03125, 0.030768749999999997, 0.030682227021604936])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO : Définir la déscente du gradient\n",
    "# Cette fonction doit afficher \n",
    "def gradient_descent(X, Y, theta, nb_iter, learning_rate, affich = True):\n",
    "    couts = []\n",
    "    theta1 = theta.copy()\n",
    "    \n",
    "    if (affich):\n",
    "        afficher_droite(X, Y, theta1)\n",
    "    \n",
    "    # TODO Définir l'algorithme de la descente de gradient : \n",
    "    for i in range(nb_iter):\n",
    "        couts.append(J(X, Y, theta1))\n",
    "        grad = gradient(X, Y, theta1)\n",
    "        theta1 -=  learning_rate * grad\n",
    "        \n",
    "        if affich and i == nb_iter/2:\n",
    "            afficher_droite(X, Y, theta1)\n",
    "        \n",
    "    if(affich):\n",
    "        afficher_droite(X, Y, theta1)\n",
    "\n",
    "    return theta1, couts\n",
    "\n",
    "# Tester la fonction\n",
    "# array([0.25202765, 0.50363117])\n",
    "# [0.03125, 0.030768749999999997, 0.030682227021604936])\n",
    "gradient_descent(X_t, Y_t, theta_t, 3, LEARNING_RATE, affich=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.2.3  Appliquer la descente sur nos données \n",
    "Lorsqu'on applique le code suivant, on aura un problème\n",
    "\n",
    "**Question** : Quel est le problème ?\n",
    "Régler le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse (Quel est le problème)** : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (36,2) and (1,) not aligned: 2 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-13b4b884539b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtheta_optimaux\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNB_ITER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Thetas optimaux : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta_optimaux\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-cf4ff0726700>\u001b[0m in \u001b[0;36mgradient_descent\u001b[1;34m(X, Y, theta, nb_iter, learning_rate, affich)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maffich\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mafficher_droite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# TODO Définir l'algorithme de la descente de gradient :\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-7d62f6d54eb8>\u001b[0m in \u001b[0;36mafficher_droite\u001b[1;34m(X, Y, theta)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mafficher_droite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"blue\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"red\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# tester avec X_t et Y_t\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-f34bca10be03>\u001b[0m in \u001b[0;36mpredire\u001b[1;34m(X, theta)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# TODO: Prédire la valeur :\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# tester la prédiction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (36,2) and (1,) not aligned: 2 (dim 1) != 1 (dim 0)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO: avant d'appliquer le gradient, il faut faire un traitement \n",
    "\n",
    "# Ajouter les 1\n",
    "ones = np.ones([X_train.shape[0],1])\n",
    "X_train = np.concatenate((ones, X_train), axis=1)\n",
    "\n",
    "theta_optimaux, couts = gradient_descent(X_train, Y_train, theta, NB_ITER, LEARNING_RATE)\n",
    "\n",
    "print(\"Thetas optimaux : \", theta_optimaux)\n",
    "print(couts[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(couts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1** : \n",
    "\n",
    "Pour cette exemple, quel est selon vous le nombre d'itérations nécessaires pour obtenir la convergence dans l'algorithme de la descente du gradient ? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse 1** :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question2** : \n",
    "\n",
    "Modifier le code de la décente du gradient pour sortir de la boucle (avant que le nombre des itérations soit fini) lorsque l'erreur ne s'améliore plus. \n",
    "\n",
    "Pour ce faire, on calcul un taux de changement et on le compare avec un seuil de changement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Définir la déscente du gradient\n",
    "def gradient_descent2(X, Y, theta, nb_iter, learning_rate, affich = True, seuil=0.001):\n",
    "    couts = []\n",
    "    theta1 = theta.copy()\n",
    "    couts.append(J(X, Y, theta1))\n",
    "    \n",
    "    if (affich):\n",
    "        afficher_droite(X, Y, theta1)\n",
    "    \n",
    "    # TODO Définir l'algorithme de la descente de gradient\n",
    "        \n",
    "    if(affich):\n",
    "        afficher_droite(X, Y, theta1)\n",
    "\n",
    "    return theta1, couts\n",
    "\n",
    "theta_optimaux, couts = gradient_descent2(X_train, Y_train, theta, NB_ITER, LEARNING_RATE, affich = False)\n",
    "plt.plot(couts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2 suite** : \n",
    "1. Donner le nombre des itérations nécessaire pour la convergence (à peu près)\n",
    "1. Quel est l'intéret de fixer un nombre des itérations ?\n",
    "1. Quel est l'intéret d'utiliser le taux d'amélioration ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse 2** : \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 3** : \n",
    "\n",
    "Essayer de changer les valeurs du learning_rate,\n",
    "Afficher le graphe des coûts (J) par rapport aux différents learning_rate. \n",
    "\n",
    "- Que remarquez-vous ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Tester plusieurs valeurs du learning_rate : \n",
    "\n",
    "#TODO iter_rate = 0.1\n",
    "couts1 = []\n",
    "#TODO iter_rate = 0.05\n",
    "couts2 = []\n",
    "#TODO iter_rate = 0.01\n",
    "couts3 = []\n",
    "\n",
    "# Affichage du graphe des coûts par rapport aux learning_rate :\n",
    "\n",
    "plt.plot(couts1, label = \"0.1\")\n",
    "plt.plot(couts2, label = \"0.05\")\n",
    "plt.plot(couts3, label = \"0.01\")\n",
    "plt.legend()\n",
    "#plt.autoscale()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse 3** : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4** : \n",
    "\n",
    "Appliquer la décente du gradient sur les 3 initialisations des paramètres (thetas) : \n",
    "\n",
    "- Initialisation aléatoire \n",
    "- Initialisation à zero \n",
    "- Initialisation à un \n",
    "\n",
    "Est-ce que l'initialisation des paramètres affecte la convergence ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Initialisation aléatoire \n",
    "couts1 = []\n",
    "\n",
    "# TODO Initialisation à zero \n",
    "couts2 = []\n",
    "\n",
    "# TODO Initialisation à un \n",
    "couts3 = []\n",
    "\n",
    "# Affichage du graphe des coûts par rapport aux learning_rate :\n",
    "\n",
    "plt.plot(couts1, label = \"Aleatoire\")\n",
    "plt.plot(couts2, label = \"zeroes\")\n",
    "plt.plot(couts3, label = \"uns\")\n",
    "plt.legend()\n",
    "#plt.autoscale()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse 4** : \n",
    "\n",
    "- [ ] OUI \n",
    "- [ ] NON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II Régression Polynomiale \n",
    "\n",
    "Dans cette partie, on essaye d'appliquer une régression polynomiale.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.1 Régression Linéaire (pour comparaison) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO initialiser theta\n",
    "theta1 = None\n",
    "\n",
    "#Application de la régression linéaire \n",
    "theta1 , couts1 = gradient_descent(X_train, Y_train, theta1, NB_ITER, LEARNING_RATE, affich=False)\n",
    "\n",
    "X_train[:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.2 Régression Polynomiale (degré 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO créer des données similaires à X_train mais avec une colonne X^2\n",
    "X_train2 = None\n",
    "\n",
    "# TODO initialiser theta\n",
    "theta2 = None\n",
    "\n",
    "#Application de la régression linéaire \n",
    "theta2 , couts2 = gradient_descent(X_train2, Y_train, theta2, NB_ITER, LEARNING_RATE, affich=False)\n",
    "\n",
    "X_train2[:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.3 Régression Plynomiale (degré 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO créer des données similaires à X_train2 mais avec une colonne X^3\n",
    "X_train3 = None\n",
    "\n",
    "# TODO initialiser theta\n",
    "theta3 = None\n",
    "\n",
    "#Application de la régression linéaire \n",
    "theta3 , couts3 = gradient_descent(X_train3, Y_train, theta3, NB_ITER, LEARNING_RATE, affich=False)\n",
    "\n",
    "X_train3[:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.4 Comparaison des évolutions des coûts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage du graphe des coûts par rapport aux degré des polynomes :\n",
    "\n",
    "plt.plot(couts1, label = \"a X + b\")\n",
    "plt.plot(couts2, label = \"a X + b X^2 + c\")\n",
    "plt.plot(couts3, label = \"a X + b X^2 + c X^3 + d\")\n",
    "plt.legend()\n",
    "#plt.autoscale()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : Que remarquez-vous ?\n",
    "\n",
    "**Réponse** : \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.5 Comparaison des estimateurs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des estimations :\n",
    "\n",
    "plt.scatter(X_train[:,1], Y_train, color=\"blue\")\n",
    "plt.plot(X_train[:,1], predire(X_train, theta1), label = \"a X + b\", color=\"red\")\n",
    "plt.plot(X_train[:,1], predire(X_train2, theta2), label = \"a X + b X^2 + c\", color=\"green\")\n",
    "plt.plot(X_train[:,1], predire(X_train3, theta3), label = \"a X + b X^2 + c X^3 + d\", color=\"orange\")\n",
    "plt.legend()\n",
    "#plt.autoscale()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le problème avec le graphe est que les données doivent être ordonnées selon la superficie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver les indexes ordonnées \n",
    "idx = X_train[:,1].argsort()\n",
    "\n",
    "X_train = X_train[idx]\n",
    "X_train2 = X_train2[idx]\n",
    "X_train3 = X_train3[idx]\n",
    "Y_train = Y_train[idx] #pas besoin de ça, mais pour avoir les Y alignés avec les X\n",
    "\n",
    "plt.scatter(X_train[:,1], Y_train, color=\"blue\")\n",
    "plt.plot(X_train[:,1], predire(X_train, theta1), label = \"a X + b\", color=\"red\")\n",
    "plt.plot(X_train[:,1], predire(X_train2, theta2), label = \"a X + b X^2 + c\", color=\"green\")\n",
    "plt.plot(X_train[:,1], predire(X_train3, theta3), label = \"a X + b X^2 + c X^3 + d\", color=\"orange\")\n",
    "plt.legend()\n",
    "#plt.autoscale()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.6 Test des modèles (Performance)\n",
    "\n",
    "Ici, on va tester les modèles : theta1, theta2 et theta3 sur (X_test, Y_test) afin de décider le meilleur modèle dans le cas de prédidication des prix des maisons en utilisant la surface. \n",
    "\n",
    "Pour ce faire, on utilise **Root Mean Squared Error (RMSE)**. Notre fonction de cout est, en réalité, **Mean Squared Error (RMSE)**. Donc, il suffit d'appliquer la racine carrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO tester les trois modèles en utilisant la fonction \n",
    "\n",
    "erreur1 = []\n",
    "erreur2 = []\n",
    "erreur3 = []\n",
    "\n",
    "erreur1, erreur2, erreur3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : Quel est le meilleur modèle selon la métrique et les données utilisées ?\n",
    "\n",
    "**Réponse** : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III Régression lineaire avec scikit-learn \n",
    "\n",
    "\n",
    "On poursuit avec les données des prix maisons : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.1 Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données \n",
    "from sklearn.model_selection import train_test_split  \n",
    "X = houses.iloc[:, :-1].values # Premières colonnes \n",
    "Y = houses.iloc[:,-1].values # Dernière colonne \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.2 Régression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner le modèle \n",
    "from sklearn.linear_model import LinearRegression  \n",
    "regressor1 = LinearRegression(normalize=True)  \n",
    "regressor1.fit(X_train, Y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le coefficient des constantes\n",
    "print(regressor1.intercept_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les coéfficients des variables (caractéristiques)\n",
    "print(regressor1.coef_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, Y_train, color=\"blue\")\n",
    "plt.plot(X, regressor1.predict(X), color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédire les valeurs du X_test \n",
    "Y_pred = regressor1.predict(X_test)  \n",
    "\n",
    "plt.scatter(X_train, Y_train, color=\"blue\")\n",
    "plt.scatter(X_test, Y_test, color=\"green\")\n",
    "plt.plot(X, regressor1.predict(X), color=\"red\")\n",
    "plt.scatter(X_test, Y_pred, color=\"violet\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.3 Régression polynomiale\n",
    "\n",
    "La régression polynomiale est un cas spécial de la régression linéaire. On peut créer de nouvelles caractéristiques dans l'étape de préparation des données en multipliant les valeurs des anciennes caractéristiques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.3.1 Créer des nouvelles caractéristiques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly2 = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "X_train2 = poly2.fit_transform(X_train)\n",
    "X_test2 = poly2.fit_transform(X_test)\n",
    "\n",
    "X_train2[:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly10 = PolynomialFeatures(degree=10, include_bias=False)\n",
    "\n",
    "X_train10 = poly10.fit_transform(X_train)\n",
    "X_test10 = poly10.fit_transform(X_test)\n",
    "\n",
    "X_train10[:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.3.2 Entrainer les deux modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regrésseur polynomial de degré 2\n",
    "regressor2 = LinearRegression(normalize=True)  \n",
    "regressor2.fit(X_train2, Y_train)\n",
    "\n",
    "# Regrésseur polynomial de degré 10\n",
    "regressor10 = LinearRegression(normalize=True)  \n",
    "regressor10.fit(X_train10, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.5 Evaluation des modèles \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred1 = regressor1.predict(X_test)\n",
    "Y_pred2 = regressor2.predict(X_test2)\n",
    "Y_pred10 = regressor10.predict(X_test10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.5.1 Explained variance score\n",
    "\n",
    "$$explained\\_variance(y, ŷ) = 1 - \\frac{Var(y - ŷ)}{Var(y)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  explained_variance_score\n",
    "\n",
    "erreur1 = explained_variance_score(Y_test, Y_pred1)\n",
    "erreur2 = explained_variance_score(Y_test, Y_pred2)\n",
    "erreur10 = explained_variance_score(Y_test, Y_pred10)\n",
    "\n",
    "erreur1, erreur2, erreur10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.5.2 Mean squared error\n",
    "\n",
    "$$MSE(y, ŷ) = \\frac{1}{nbr\\_echantillons} \\sum\\limits_{i=0}^{nbr\\_echantillons - 1} (y - ŷ)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "erreur1 = mean_squared_error(Y_test, Y_pred1)\n",
    "erreur2 = mean_squared_error(Y_test, Y_pred2)\n",
    "erreur10 = mean_squared_error(Y_test, Y_pred10)\n",
    "\n",
    "erreur1, erreur2, erreur10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.5.3 Mean absolute error\n",
    "\n",
    "$$MAE(y, ŷ) = \\frac{1}{nbr\\_echantillons} \\sum\\limits_{i=0}^{nbr\\_echantillons - 1} |y - ŷ|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "erreur1 = mean_absolute_error(Y_test, Y_pred1)\n",
    "erreur2 = mean_absolute_error(Y_test, Y_pred2)\n",
    "erreur10 = mean_absolute_error(Y_test, Y_pred10)\n",
    "\n",
    "erreur1, erreur2, erreur10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.5.4 Autres\n",
    "\n",
    "Consulter https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.6 Persistance des modèles \n",
    "\n",
    "Après avoir entrainé un modèle, il est souhaitable de le conserver pour un usage ultérieur sans avoir besoin d'entrainer une deuxième fois. Il y a deux façons de le faire selon la doc de scikit-learn (https://scikit-learn.org/stable/modules/model_persistence.html)\n",
    "\n",
    "- la sérialisation pickle\n",
    "- la sérialisation joblib\n",
    "\n",
    "La deuxième est recommandée par scikit-learn. Après avoir entrainer notre modèle, on le sauvegarde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Pour sauvegarder le modèle\n",
    "dump(regressor1, \"mon_modele.joblib\")\n",
    "\n",
    "# Pour Récupérer le modèle\n",
    "regressor_past = load(\"mon_modele.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

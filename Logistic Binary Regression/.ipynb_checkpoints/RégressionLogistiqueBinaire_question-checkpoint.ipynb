{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 03 : Régression logistique Binaire \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Implémentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Des données pour tester les fonctions\n",
    "# Testes unitaires\n",
    "X_t = np.array([[2., -8.], [1., -2.], [1., 2.]])\n",
    "Y_t = np.array([0., 1., 1.])\n",
    "Theta_t = np.array([0.5, 0.25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1- Fonctions utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# une fonction qui normalise une matrice sur chaque colonne \n",
    "# dans l'entrainnement, on calcule les moyennes et les déviations de chaque colonne\n",
    "# dans le teste, on ne doit pas recalculer ces deux paramètres. \n",
    "# Mais, on doit utiliser ceux calculés dans l'entrainnement\n",
    "def normaliser(X, mean=None, std=None): \n",
    "    if (mean is None) or (std is None): \n",
    "        mean = np.mean(X, axis=0)\n",
    "        std = np.std(X, axis=0)\n",
    "    X_norm = (X - mean)/std\n",
    "    return X_norm, mean, std\n",
    "\n",
    "#Résultat : \n",
    "#(array([[ 1.41421356, -1.29777137],\n",
    "#        [-0.70710678,  0.16222142],\n",
    "#        [-0.70710678,  1.13554995]]),\n",
    "# array([ 1.33333333, -2.66666667]),\n",
    "# array([0.47140452, 4.10960934]))\n",
    "normaliser(X_t), normaliser(X_t, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer la matrice des caractéristiques pour l'entrainnement ou la prédiction\n",
    "# On applique la normalisation sur chaque colonne (sauf si : norm=False)\n",
    "# Ensuite on ajoute une colonne des 1 (sauf si : const=False)\n",
    "def preparer(X, norm=True, const=True, mean=None, std=None): \n",
    "    X_pre = X.copy()\n",
    "    if norm: \n",
    "        X_pre, mean, std = normaliser(X_pre)\n",
    "    if const:\n",
    "        X_pre = np.append(np.ones((X_pre.shape[0],1)), X_pre ,axis=1)\n",
    "    return X_pre, mean, std\n",
    "#Résulat : \n",
    "\n",
    "preparer(X_t), preparer(X_t, norm=False), preparer(X_t, const=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Défininir des fonctions qui génèrent des vecteurs ou des matrices\n",
    "# Ces fonctions seront utilisées pour générer les Thétas\n",
    "\n",
    "def generer_zeros_1(nbr):\n",
    "    return np.zeros(nbr)\n",
    "\n",
    "def generer_uns_1(nbr):\n",
    "    return np.ones(nbr)\n",
    "\n",
    "def generer_aleatoire_1(nbr):\n",
    "    return np.random.rand(nbr)\n",
    "    \n",
    "generer_zeros_1(2), generer_uns_1(2), generer_aleatoire_1(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afficher_2(X, Y, L=None, Y_labels=[\"Admis\", \"Non admis\"], X_labels=[\"Note 1\", \"Note 2\"]):\n",
    "    oui = Y == 1\n",
    "    plt.scatter(X[oui, 0], X[oui, 1], color=\"green\", marker=\"o\", label=Y_labels[0])\n",
    "    plt.scatter(X[~oui, 0], X[~oui, 1], color=\"red\", marker=\"x\", label=Y_labels[1])\n",
    "    if L is not None:\n",
    "        x_values, y_values = L\n",
    "        plt.plot(x_values, y_values, label=\"ligne de decision\")\n",
    "    plt.xlabel(X_labels[0])\n",
    "    plt.ylabel(X_labels[1])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# th0 + th1 * x1 + th2 * x2 = 0\n",
    "def ligne_decision(X, Theta):\n",
    "    X1 = [np.min(X[:,0]), np.max(X[:,0])]\n",
    "    X2 = np.max(X[:,1])\n",
    "    X2_min = X2 - (Theta[0] + Theta[1] * X1[0]) / Theta[2]\n",
    "    X2_max = X2 - (Theta[0] + Theta[1] * X1[1]) / Theta[2]\n",
    "    return X1, [X2_min, X2_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2- Combinaison linéaire\n",
    "On combine les m caractéristiques linéairement\n",
    "\n",
    "$$z=\\theta_0+\\sum\\limits_{i=1}^{m} \\theta_i x_i = \\theta^T X$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO la fonction qui calcule la combination linéaire entre les caractéristiques\n",
    "# Vous l'avez déjà vu dans la régression linéaire\n",
    "def z_1(X, Theta): \n",
    "    return None\n",
    "\n",
    "#Résulat : array([-0.5,  0. ,  1.5])\n",
    "z_1(X_t, Theta_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2- Calcul de probabilité\n",
    "La valeur combinée est transformée à une probabilité en utilisant la fonction logistique \n",
    "\n",
    "$$\\sigma(z)=\\frac{1}{1 + e^{-z}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO La fonction ségmoid\n",
    "# Elle doit fonctionner sur des scalaires ou des vecteurs de numpy\n",
    "def sigmoid(X):\n",
    "    # Fonction d'activation utilisée pour rendre les valeurs réelles entre 0 et 1 \n",
    "    return  None\n",
    "\n",
    "# résultat: (0.5, array([0.26894142, 0.73105858]))\n",
    "sigmoid(0), sigmoid(np.array([-1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_1(X, Theta, mean=None, std=None, const=False): \n",
    "    norm = (mean is not None) and (std is not None)\n",
    "    X_pre, mean, std = preparer(X, norm, const, mean=mean, std=std)\n",
    "    return sigmoid(z_1(X_pre, Theta))\n",
    "\n",
    "# Résultat : array([0.26894142, 0.5       , 0.73105858])\n",
    "h_1(X_t, Theta_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3- La fonction du cout \n",
    "\n",
    "$$ cout(h_\\theta(x), y) = \\begin{cases}\n",
    "- \\log(h_\\theta(x)) & \\text{ si } y = 1\\\\ \n",
    "- \\log(1 - h_\\theta(x))  & \\text{ si } y = 0\n",
    "\\end{cases}$$\n",
    "\n",
    "Puisque $ y \\in \\{0, 1\\}$ donc, \n",
    "\n",
    "$$ cout(h_\\theta(x), y) = - y \\log(h_\\theta(x)) - (1-y) \\log(1 - h_\\theta(x))$$\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{m} \\sum\\limits_{i=1}^{m} cout(h_\\theta(x^{(i)}), y^{(i)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : La fonction de cout utilisée dans la régression logistique \n",
    "# H est la prédiction \n",
    "# Y est la valeur réel\n",
    "def J_1(H, Y): \n",
    "    return None \n",
    "\n",
    "# Résultat : 0.4398901851987969\n",
    "J_1(h_1(X_t, Theta_t), Y_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4- Les gradients\n",
    "\n",
    "$$\\frac{\\partial J(\\theta)}{\\theta_j} = \\frac{1}{m} \\sum\\limits_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) x_{ij} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Définir la fonction de gradient :\n",
    "def gradient_1(X, H, Y):\n",
    "    return None\n",
    "\n",
    "# Résultat : array([-0.07701953, -0.56313807])\n",
    "gradient_1(X_t, h_1(X_t, Theta_t), Y_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5- Entraînnement (algorithme du gradient)\n",
    "\n",
    "Les coéfficients sont mis à jour itérativement en se basant sur le gradient et un pas d'apprentissage $\\alpha$. Puisque cette fonction a été implémentée dans le TP précédent, elle est donnée ici, mais d'une façon plus parametrable.\n",
    "\n",
    "$$\\theta_j = \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\theta_j} $$\n",
    "\n",
    "Notre fonction d'entrainnement prend les paramètres suivantes : \n",
    "- X : matrice (échantillons X caractéristiques)\n",
    "- Y : vecteur (ou matrice) des résultas (échantillons X nombre_classes)\n",
    "- norm : si on normalise X ou nom (par défaut : True)\n",
    "- const : si on ajoute $\\theta_0$ ou non (par défaut : True)\n",
    "- nbr_iter : nombre des itérations avant de sortir\n",
    "- alpha : le pas d'apparentissage (Learning rate)\n",
    "- eps : le test d'arrêt si la différence entre les couts (actuel et précédent) est inférieur à $\\epsilon$ on arrête la désente même si on n'a pas terminé toutes les itérations\n",
    "- theta_func : la fonction qui génère les $\\theta$ (par défaut : zéros)\n",
    "- h_func : la fonction qui calcule les probabilités (par défaut : h_1)\n",
    "- J_func : la fonction du cout (par défaut : J_1)\n",
    "- grad_func : la fonction qui calcule le gradient (par défaut : gradient_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puisque c'était fait en premier TP, la fonction est donnée \n",
    "# Ce n'ai pas la peine de modifier\n",
    "def entrainer_1(X, Y, norm=True, const=True, nbr_iter=200, alpha=1., eps=0.01, \n",
    "                theta_func=generer_zeros_1, h_func=h_1, J_func=J_1, grad_func=gradient_1): \n",
    "    \n",
    "    X_pre, mean, std = preparer(X, norm, const)\n",
    "    Theta = theta_func(X_pre.shape[1])\n",
    "    \n",
    "    couts = []\n",
    "    couts.append(J_func(h_func(X_pre, Theta), Y))\n",
    "    \n",
    "    for i in range(nbr_iter):\n",
    "        H = h_func(X_pre, Theta)\n",
    "        Theta -= alpha * grad_func(X_pre, H, Y)\n",
    "        couts.append(J_func(H, Y))\n",
    "    \n",
    "    return Theta, mean, std, couts\n",
    "\n",
    "theta1, mean1, std1, couts1 = entrainer_1(X_t, Y_t)\n",
    "\n",
    "# Résultat : \n",
    "# (array([ 1.68948098, -2.97269188,  2.16631904]),\n",
    "# array([ 1.33333333, -2.66666667]),\n",
    "# array([0.47140452, 4.10960934]),\n",
    "# 0.007583559780610472)\n",
    "theta1, mean1, std1, couts1[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6- Prédiction \n",
    "\n",
    "Etant donnée un seuil et des probabilités, pour chaque probabilité on rend 1 si elle dépasse ou égale le seuil, 0 sinon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compléter cette fonction \n",
    "# H est un vecteur de probabilités \n",
    "def predire_1(H, seuil=0.5): \n",
    "    return None\n",
    "\n",
    "# Résultat : array([0, 1, 1])\n",
    "predire_1(h_1(X_t, Theta_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7- Regrouper les fonctions ensemble \n",
    "\n",
    "Pour bien gérer l'entrainnement et la prédiction, on rassemble les fonctions que vous avez implémenté dans une seul classe. L'intérêt : \n",
    "- Si on applique la normalisation durant l'entrainnement, on doit l'appliquer aussi durant la prédiction. En plus, on doit utiliser les mêmes paramètres (moyenne et écart-type)\n",
    "- On utilise les thétas optimales lors de la prédicition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ne modifier pas ici\n",
    "class RegLogistique(object):\n",
    "    \n",
    "    def __init__(self, nbr_iter=100, alpha=1., theta_func=generer_zeros_1, norm=True, const=True): \n",
    "        self.nbr_iter = nbr_iter\n",
    "        self.alpha = alpha\n",
    "        self.theta_func = theta_func\n",
    "        self.norm = norm\n",
    "        self.const = const\n",
    "    \n",
    "    def entrainer(self, X, Y): \n",
    "        self.Theta, self.mean, self.std, self.couts = entrainer_1(X, Y, \n",
    "                                                                  nbr_iter=self.nbr_iter, \n",
    "                                                                  alpha=self.alpha, \n",
    "                                                                  theta_func=self.theta_func, \n",
    "                                                                  norm=self.norm, \n",
    "                                                                  const=self.const)\n",
    "        \n",
    "    # La prédiction\n",
    "    # si prob=True elle rend un vecteur de probabilités\n",
    "    # sinon elle rend une vecteur de 1 et 0\n",
    "    def predire(self, X, prob=True, seuil=0.5):\n",
    "        H = h_1(X, self.Theta, self.mean, self.std, self.const)\n",
    "        if prob:\n",
    "            return H\n",
    "        return predire_1(H, seuil=seuil)\n",
    "\n",
    "reg_lin = RegLogistique(const=False)\n",
    "reg_lin.entrainer(X_t, Y_t)\n",
    "reg_lin.predire(np.array([[2., -2.],[-1., 1.]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Application sur un exemple simple \n",
    "\n",
    "**Cette partie est juste pour tester votre code sur un petit exemple (pas de questions à complir)**\n",
    "\n",
    "Nous avons générer une dataset avec deux notes sur 20. Si la moyenne est supérieure ou égale à 10 la classe est \"admis\" (1), sinon (0)\n",
    "\n",
    "Si vous êtes intéressé par le code utilisé pour générer cette dataset, consulter (datasets/notes_generation.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = pd.read_csv(\"datasets/notes.csv\")\n",
    "notes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des features \n",
    "X_notes = notes.iloc[:, :-1].values # Premières colonnes \n",
    "\n",
    "Y_notes = notes.iloc[:,-1].values # Dernière colonne \n",
    "\n",
    "afficher_2(X_notes, Y_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_notes = RegLogistique()\n",
    "reg_notes.entrainer(X_notes, Y_notes)\n",
    "\n",
    "line_decision = ligne_decision(X_notes, reg_notes.Theta)\n",
    "\n",
    "afficher_2(X_notes, Y_notes, L=line_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(reg_notes.couts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Exécution sur un exemple réel\n",
    "\n",
    "On veut aider les médecins à bien décider si les patients contaminés par COVID-19 doivent être hospitalisés ou traités à leurs maisons. Dans ce cas, on veut estimer si un malade va guérir ou non. \n",
    "\n",
    "Pour ce faire, on va utiliser [Novel Corona Virus 2019 Dataset](https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset). Pour des fins de simplicité, on se contante par les caractéristiques : le pays et l'age. \n",
    "\n",
    "### 3.1- Lecture de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona = pd.read_csv(\"datasets/COVID19_line_list_data.csv\")\n",
    "corona.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2- Préparation de dataset\n",
    "\n",
    "On veut préparer la dataset afin qu'elle soit adéquate à notre problème (prédire si un malade va rétablir ou non)\n",
    "\n",
    "**Pour bien répondre à cette section, utiliser pandas. Consulter le premier TP (Préparation de données)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona[\"recovered\"].unique()\n",
    "# On remarque que la caractéristique \"recovered\" a plusieurs valeurs possibles\n",
    "# Ici 0 veut dire le patient n'est pas rétabli \n",
    "# 1 veut dire le patient est rétabli\n",
    "# Les autres valeurs sont des dates et elles veulent dire que le partient est rétabli\n",
    "\n",
    "# La caractéristique \"death\" a le même sens des valeurs, mais en remplaçant \"rétabli\" par \"mort\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO on veut garder seulement les échantillons où les patients sont rétablis (recovered) ou morts (death)\n",
    "\n",
    "# Résultat : 222\n",
    "corona.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO on veut garder garder seulement les caractéristiques \"country\", \"age\" et \"recovered\"\n",
    "# Astuce : voir DataFrame.filter\n",
    "\n",
    "corona.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on veut que les valeurs de \"recovered\" soient 1 ou 0\n",
    "corona[\"recovered\"] = corona[\"recovered\"].map(lambda x: 0 if x == \"0\" else 1)\n",
    "\n",
    "corona.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO filtrer les échantillons avec des valeurs (gender et age) nulles\n",
    "\n",
    "corona.info()\n",
    "# Les trois colonnes doivent avoir 203 non-null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On veut garder seulement les 3 premiers pays en question de nombre\n",
    "corona[\"country\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = corona[\"country\"].isin([\"Singapore\", \"China\", \"South Korea\"])\n",
    "corona = corona.loc[msk]\n",
    "corona[\"country\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des caractéristiques \n",
    "X_corona = corona.iloc[:, :-1].values # Premières colonnes \n",
    "\n",
    "Y_corona = corona.iloc[:,-1].values # Dernière colonne \n",
    "\n",
    "X_corona[:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3- Encodage des caractéristiques\n",
    "\n",
    "La régression s'applique seulement sur des caractéristiques numériques et pas nominales. \n",
    "On veut tester l'effet de choisir le bon encodeur. \n",
    "Pour ce faire, on va tester avec deux encodeurs : \n",
    "- Encodage ordinal : les valeurs d'une caractéristique sont attribuées des nombres selon l'ordre de la première occurence \n",
    "- Encodage One Hot : chaque valeur d'une caractéristique devient une colonne avec une valeur de 1 ou 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "X_corona_pays = encoder.fit_transform(X_corona[:, 0].reshape(len(X_corona), 1))\n",
    "\n",
    "X_corona_ordinal = np.concatenate((X_corona_pays, X_corona[:, 1].reshape((len(X_corona), 1))), axis=1)\n",
    "\n",
    "X_corona_ordinal[:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "X_corona_pays = encoder.fit_transform(X_corona[:, 0].reshape(len(X_corona), 1))\n",
    "\n",
    "X_corona_onehot = np.concatenate((X_corona_pays, X_corona[:, 1].reshape((len(X_corona), 1))), axis=1)\n",
    "\n",
    "X_corona_onehot[:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4- Entrainnement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomization des données pour marquer les 80% lignes\n",
    "msk = np.random.rand(len(X_corona)) < 0.8 \n",
    "\n",
    "Y_corona_train = np.array(Y_corona[msk], dtype=np.float32)\n",
    "Y_corona_test = np.array(Y_corona[~msk], dtype=np.float32)\n",
    "\n",
    "X_corona_ordinal_train = np.array(X_corona_ordinal[msk, :], dtype=np.float32)\n",
    "X_corona_ordinal_test = np.array(X_corona_ordinal[~msk, :], dtype=np.float32)\n",
    "\n",
    "X_corona_onehot_train = np.array(X_corona_onehot[msk, :], dtype=np.float32)\n",
    "X_corona_onehot_test = np.array(X_corona_onehot[~msk, :], dtype=np.float32)\n",
    "\n",
    "Y_corona_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_corona_ordinal = RegLogistique()\n",
    "reg_corona_onehot = RegLogistique()\n",
    "\n",
    "# TODO compléter le  code afin d'entrainer deux modèles \n",
    "reg_corona_ordinal.entrainer(X_corona_ordinal_train, Y_corona_train)\n",
    "reg_corona_onehot.entrainer(X_corona_onehot_train, Y_corona_train)\n",
    "\n",
    "\n",
    "#Affichage des évolutions des couts \n",
    "plt.plot(reg_corona_ordinal.couts, color=\"red\", label=\"ordinal\")\n",
    "plt.plot(reg_corona_onehot.couts, color=\"green\", label=\"one hot\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : Que remarquez-vous ? Analysez \n",
    "\n",
    "**Réponse** : \n",
    "\n",
    "\n",
    "**Analyse** : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_corona_ordinal.Theta, reg_corona_onehot.Theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5- Test \n",
    "\n",
    "On mesure la qualité d'un système de classification en utilisant la matrice de confusion : \n",
    "\n",
    "| -  | Estimé (1) | Estimé (0) |\n",
    "| --- | ---| ---|\n",
    "| Réel (1) | TP (vrais positifs) | FN (faux négatifs)|\n",
    "| Réel (0) | TP (faux positifs) | TN (vrais négatifs) |\n",
    "\n",
    "Il y a deux métriques : \n",
    "- la précision (ou valeur prédictive positive) est la proportion des items pertinents parmi l'ensemble des items proposés ; \n",
    "- le rappel (ou sensibilité) est la proportion des items pertinents proposés parmi l'ensemble des items pertinents. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compléter le test; ici, on veut la prédiction sous forme de 1 et 0 et pas des probabulités\n",
    "# Le seuil est 0.5 (par défaut)\n",
    "H_corona_ordinal_test = None\n",
    "H_corona_onehot_test = None\n",
    "\n",
    "# Afficher la somme des 1 pour chaque \n",
    "H_corona_ordinal_test.sum(), H_corona_onehot_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compléter les fonctions qui calculent la matrice de confusion \n",
    "def calculerTP(Y_reel, Y_predit): \n",
    "    return None\n",
    "\n",
    "def calculerFN(Y_reel, Y_predit): \n",
    "    return None\n",
    "\n",
    "def calculerFP(Y_reel, Y_predit): \n",
    "    return None\n",
    "\n",
    "def calculerTN(Y_reel, Y_predit): \n",
    "    return None\n",
    "\n",
    "TP_corona_ordinal = calculerTP(Y_corona_test, H_corona_ordinal_test)\n",
    "FN_corona_ordinal = calculerFN(Y_corona_test, H_corona_ordinal_test)\n",
    "FP_corona_ordinal = calculerFP(Y_corona_test, H_corona_ordinal_test)\n",
    "TN_corona_ordinal = calculerTN(Y_corona_test, H_corona_ordinal_test)\n",
    "\n",
    "TN_corona_ordinal, FP_corona_ordinal, FN_corona_ordinal, TP_corona_ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour vérifier votre solution \n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(Y_corona_test, H_corona_ordinal_test).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_corona_onehot = calculerTP(Y_corona_test, H_corona_onehot_test)\n",
    "FN_corona_onehot = calculerFN(Y_corona_test, H_corona_onehot_test)\n",
    "FP_corona_onehot = calculerFP(Y_corona_test, H_corona_onehot_test)\n",
    "TN_corona_onehot = calculerTN(Y_corona_test, H_corona_onehot_test)\n",
    "\n",
    "TN_corona_onehot, FP_corona_onehot, FN_corona_onehot, TP_corona_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compléter les fonctions suivantes\n",
    "def rappel(TN, FP, FN, TP): \n",
    "    return None\n",
    "\n",
    "def precision(TN, FP, FN, TP): \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison du recouvrement \n",
    "R_corona_ordianl = rappel(TN_corona_ordinal, FP_corona_ordinal, FN_corona_ordinal, TP_corona_ordinal)\n",
    "R_corona_onehot = rappel(TN_corona_onehot, FP_corona_onehot, FN_corona_onehot, TP_corona_onehot)\n",
    "\n",
    "R_corona_ordianl, R_corona_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : Que pouvez-vous constater ? \n",
    "\n",
    "**Réponse** : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison de la précision \n",
    "P_corona_ordianl = precision(TN_corona_ordinal, FP_corona_ordinal, FN_corona_ordinal, TP_corona_ordinal)\n",
    "P_corona_onehot = precision(TN_corona_onehot, FP_corona_onehot, FN_corona_onehot, TP_corona_onehot)\n",
    "\n",
    "P_corona_ordianl, P_corona_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : Que pouvez-vous constater ? \n",
    "\n",
    "**Réponse** : "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
